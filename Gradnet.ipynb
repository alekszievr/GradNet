{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-488f90248e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mtrain_iter_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m    \u001b[0mgrads_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m    \u001b[0mgrads_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m    \u001b[0mtarget_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-488f90248e47>\u001b[0m in \u001b[0;36mgrad_gen_new\u001b[0;34m(updater, iterator, mins, ranges, test, xp, realbatchsize, percentage, exponent)\u001b[0m\n\u001b[1;32m     44\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m       \u001b[0min_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruelabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m       \u001b[0mrandom_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizers\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-488f90248e47>\u001b[0m in \u001b[0;36mconv_distortion\u001b[0;34m(databatch, device, test)\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0minputdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m    \u001b[0mdistorted_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistortion_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdistorted_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/idms/home/alexievr/GradNet/augmentation.py\u001b[0m in \u001b[0;36mdistortion_batch\u001b[0;34m(images, device, test)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistortion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/idms/home/alexievr/GradNet/augmentation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistortion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/idms/home/alexievr/GradNet/augmentation.py\u001b[0m in \u001b[0;36mdistortion\u001b[0;34m(image, test, xp)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# image = random_brightness(image, test=test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_contrast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhiten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/idms/home/alexievr/GradNet/augmentation.py\u001b[0m in \u001b[0;36mwhiten\u001b[0;34m(image, xp)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0madjusted_stddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0madjusted_stddev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from chainer.cuda import cupy as cp\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from copy import deepcopy\n",
    "from chainer.datasets import get_cifar10\n",
    "from linalg import maxpercentile, rank_maxpercentile, rank_minpercentile\n",
    "import time\n",
    "import net\n",
    "import augmentation\n",
    "import pdb\n",
    "\n",
    "def conv_distortion(databatch, device, test=False):\n",
    "   \"\"\"converter a cifar datasethez: elvegzi az augmentaciot es meghagyja a cimkeket\"\"\"\n",
    "   batchsize = len(databatch)\n",
    "   inputdata = [datatuple[0] for datatuple in databatch]\n",
    "   labels = np.array([datatuple[1] for datatuple in databatch])\n",
    "   if device>=0:\n",
    "      inputdata = chainer.cuda.to_gpu(inputdata, device)\n",
    "      labels = chainer.cuda.to_gpu(labels, device)\n",
    "   distorted_input = augmentation.distortion_batch(inputdata, device, test=test)\n",
    "   return (distorted_input, labels)   \n",
    "\n",
    "def grads (optimizer, data, label, mins=None, ranges=None, xp=np, percentage=15, exponent=0.5):\n",
    "   opt = deepcopy (optimizer)\n",
    "   model = opt.target\n",
    "   net = opt.target.predictor\n",
    "   model.cleargrads ()\n",
    "   opt.update (model, data, label)\n",
    "   listoflinks = list(net.links(skipself=True))\n",
    "   gradients = xp.concatenate([maxpercentile(xp.ravel(link.W.grad), 15, xp) for link in listoflinks])\n",
    "   gradients = xp.ndarray.astype (gradients, xp.float32)\n",
    "   # scale norm + power norm:\n",
    "   normalized = xp.divide ((gradients-mins), xp.where (ranges!=0, ranges, 1))\n",
    "   n = xp.where (gradients!=0, normalized, 0)\n",
    "   out = xp.sign(n)*xp.power(xp.abs(n), exponent)\n",
    "   return out\n",
    "\n",
    "def grad_gen_new (updater, iterator, mins=None, ranges=None, test=False, xp=np, realbatchsize=25, percentage=15, exponent=0.125):\n",
    "   for (i, batch)  in enumerate (iterator):\n",
    "      batchsize=len (batch)\n",
    "      in_arr, truelabels = updater.converter (batch, updater.device)\n",
    "      random_labels = xp.random.randint (10, size=(batchsize,))\n",
    "      optimizer = updater._optimizers ['main']\n",
    "      gradients = xp.concatenate(([xp.expand_dims(grads(optimizer, xp.expand_dims(in_arr[j], 0), xp.expand_dims(random_labels[j], 0), mins, ranges, xp, percentage, exponent), axis=0) for j in range(batchsize)]))\n",
    "      gradients = xp.ndarray.astype (gradients, xp.float32)\n",
    "      for k in range (int (batchsize/realbatchsize)):\n",
    "         g = gradients [k*realbatchsize:(k+1)* realbatchsize, :]\n",
    "         o = truelabels [k*realbatchsize:(k+1)*realbatchsize]\n",
    "         yield g, o\n",
    "\n",
    "batchsize=50\n",
    "learnrate=0.05\n",
    "out=\"result\"\n",
    "epoch=200\n",
    "gpu=0\n",
    "original=23047\n",
    "normalization=\"std\"\n",
    "percentage=15\n",
    "exponent=0.5\n",
    "sizes = [5, 100, 25]\n",
    "\n",
    "train, test = get_cifar10()\n",
    "\n",
    "model_old = L.Classifier(net.cnn_cifar())\n",
    "\n",
    "optimizer_old = chainer.optimizers.SGD(learnrate)\n",
    "optimizer_old.setup(model_old)\n",
    "optimizer_old.add_hook(chainer.optimizer.WeightDecay(5e-4))\n",
    "    \n",
    "train_iter_old = chainer.iterators.SerialIterator (train [0:int (len (train)/2) ], 1, repeat=False, shuffle=False)\n",
    "test_iter_old = chainer.iterators.SerialIterator(test, batchsize,\n",
    "                                                repeat=False, shuffle=False)\n",
    "# Set up a trainer\n",
    "updater_old = training.StandardUpdater(train_iter_old, optimizer_old, converter=conv_distortion, device=gpu)\n",
    "trainer_old = training.Trainer(updater_old, (1000, 'epoch'), out=out)\n",
    "\n",
    "chainer.serializers.load_npz ('./result_original/snapshot_iter_{}'.format(original), trainer_old, strict=False)\n",
    "\n",
    "if gpu >= 0:\n",
    "   # Make a specified GPU current\n",
    "   chainer.cuda.get_device_from_id(gpu).use()\n",
    "   model_old.to_gpu(gpu)  # Copy the model to the GPU\n",
    "   xp = cp\n",
    "else:\n",
    "   xp = np\n",
    "\n",
    "mins=xp.load(\"CNNgradmin_{}.npy\".format(original))\n",
    "maxes=xp.load(\"CNNgradmax_{}.npy\".format(original))\n",
    "ranges = maxes-mins\n",
    "\n",
    "linksizes = [link.W.size for link in list(model_old.predictor.links(skipself=True))]\n",
    "dividers = xp.cumsum(xp.array(linksizes))[:-1].tolist()\n",
    "\n",
    "model=net.gradnet(input_dividers = dividers, middle_sizes = sizes)\n",
    "\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(model)\n",
    "\n",
    "if gpu >=0 :\n",
    "   chainer.cuda.get_device_from_id(gpu).use()\n",
    "   model.to_gpu(gpu)\n",
    "\n",
    "train_iter_new = chainer.iterators.SerialIterator (train [int (len (train)/2)  : len (train)], 25, repeat=True, shuffle=True)\n",
    "gg = grad_gen_new (updater_old, train_iter_new, mins, ranges, test=False, xp=xp, realbatchsize=25, percentage=percentage, exponent=exponent)\n",
    "\n",
    "t0=time.time()\n",
    "while train_iter_new.epoch < epoch:\n",
    "   grads_train, target_train = gg.__next__()\n",
    "   grads_train = chainer.Variable(grads_train)\n",
    "   target_train = chainer.Variable(target_train)\n",
    "   if gpu >=0:\n",
    "      grads_train.to_gpu(gpu)\n",
    "      target_train.to_gpu(gpu)\n",
    "\n",
    "   # Calculate the prediction of the network\n",
    "   prediction_train = model(grads_train)\n",
    "   # Calculate the loss with softmax_cross_entropy\n",
    "   loss = chainer.functions.softmax_cross_entropy(prediction_train, target_train)\n",
    "   # Calculate the gradients in the network\n",
    "   model.cleargrads()\n",
    "   loss.backward()\n",
    "   # Update all the trainable paremters\n",
    "   optimizer.update()\n",
    "   if optimizer.t%50==0:\n",
    "      print(optimizer.t)\n",
    "                      \n",
    "   if optimizer.t%500==0:\n",
    "      print (optimizer.t)\n",
    "      chainer.serializers.save_npz('gradnet_{}_{}_{}_{}_{}/snapshot_iter_{}'.format(original, normalization, s1, s2, s3, optimizer.t), model)\n",
    "      t1=time.time()\n",
    "      print(\"time:\", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
